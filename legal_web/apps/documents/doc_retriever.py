# teamproject/legal_web/apps/documents/doc_retriever.py

import re
import textwrap
import numpy as np
import faiss

import fitz  
import docx  

from django.conf import settings
from qdrant_client import QdrantClient, models

import uuid

# --- íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
def get_document_text(uploaded_file):
    print(f"ğŸ”„ get_document_text í•¨ìˆ˜ ì‹œì‘: {uploaded_file.name}")
    
    filename = uploaded_file.name
    ext = filename.split('.')[-1].lower()
    text = ""

    try:
        if ext == 'pdf':
            doc = fitz.open(stream=uploaded_file.read(), filetype='pdf')
            text = "\n".join(page.get_text() for page in doc)
        elif ext == 'docx':
            document = docx.Document(uploaded_file)
            text = "\n".join(p.text for p in document.paragraphs)
        elif ext == 'txt':
            text = uploaded_file.read().decode('utf-8')
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {ext}")
    except Exception as e:
        print(f"âŒ get_document_text í•¨ìˆ˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise ValueError(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    print(f"âœ… íŒŒì¼ '{filename}'ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(text)}ì)")
    print(f"ğŸ get_document_text í•¨ìˆ˜ ì¢…ë£Œ: {filename}")
    return text


# --- í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ë²¡í„°í™” ---
def split_text_into_chunks(text: str, max_tokens=1500):
    """
    í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„(ì¡°í•­) ë˜ëŠ” ê¸¸ì´ë¡œ ìë¦…ë‹ˆë‹¤.
    """
    print(f"ğŸ”„ split_text_into_chunks í•¨ìˆ˜ ì‹œì‘: í…ìŠ¤íŠ¸ ê¸¸ì´ {len(text)}ì, max_tokens={max_tokens}")
    
    # 'ì œNì¡°' íŒ¨í„´ìœ¼ë¡œ ìš°ì„  ë¶„í•  ì‹œë„
    pattern = r"(ì œ\d+ì¡°[^\n]*\n(?:.|\n)*?(?=\nì œ\d+ì¡°|\Z))"
    matches = re.findall(pattern, text)
    
    if matches:
        chunks = [m.strip() for m in matches if m.strip()]
        print(f"ğŸ“„ ì¡°í•­ ê¸°ë°˜ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì¡°í•­")
    else:
        # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ê¸¸ì´ ê¸°ë°˜ìœ¼ë¡œ ë¶„í• 
        chunks = textwrap.wrap(text, max_tokens, break_long_words=False, replace_whitespace=False)
        print(f"ğŸ“„ ê¸¸ì´ ê¸°ë°˜ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
    
    print(f"ğŸ split_text_into_chunks í•¨ìˆ˜ ì¢…ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
    return chunks


def get_embeddings(client, texts: list[str]): 
    """
    OpenAI ì„ë² ë”© APIë¥¼ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•œ ë²¡í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    print(f"ğŸ”„ get_embeddings í•¨ìˆ˜ ì‹œì‘: {len(texts)}ê°œ í…ìŠ¤íŠ¸")
    
    try:
        response = client.embeddings.create(
            input=texts,
            model="text-embedding-3-small"
        )
        embeddings = [np.array(embedding.embedding, dtype='float32') for embedding in response.data]
        print(f"ğŸ¤– OpenAI ì„ë² ë”© API í˜¸ì¶œ ì„±ê³µ: {len(embeddings)}ê°œ ë²¡í„° ìƒì„±")
        print(f"ğŸ get_embeddings í•¨ìˆ˜ ì¢…ë£Œ: ë²¡í„° ì°¨ì› {len(embeddings[0]) if embeddings else 0}")
        return embeddings
    except Exception as e:
        print(f"âŒ get_embeddings í•¨ìˆ˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


#  Qdrant ê´€ë ¨ í•¨ìˆ˜ (íšŒì›ìš©)
# ======================================================================

def get_qdrant_client():
    """Qdrant í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("ğŸ”„ get_qdrant_client í•¨ìˆ˜ ì‹œì‘")
    
    try:
        # settings.pyì— ì •ì˜ëœ ê°’ì„ ì‚¬ìš©í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = QdrantClient(
            url=settings.QDRANT_URL,
            api_key=settings.QDRANT_API_KEY,
        )
        print("ğŸ”— Qdrant í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
        print("ğŸ get_qdrant_client í•¨ìˆ˜ ì¢…ë£Œ")
        return client
    except Exception as e:
        print(f"âŒ get_qdrant_client í•¨ìˆ˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

def upsert_document_to_qdrant(client: QdrantClient, chunks: list[str], embedding_client, user_id: int, session_id: str):
    """
    ë¬¸ì„œ ì¡°ê°ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ Qdrantì— ì €ì¥(upsert)í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ”„ upsert_document_to_qdrant í•¨ìˆ˜ ì‹œì‘: user_id={user_id}, session_id={session_id}, chunks={len(chunks)}ê°œ")
    
    if not chunks:
        print("âš ï¸ ì €ì¥í•  ì²­í¬ê°€ ì—†ì–´ í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤")
        print("ğŸ upsert_document_to_qdrant í•¨ìˆ˜ ì¢…ë£Œ: ì²­í¬ ì—†ìŒ")
        return
        
    collection_name = "legal_documents" # ëª¨ë“  ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ì»¬ë ‰ì…˜ì— ì €ì¥
    
    # 1. ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±
    try:
        client.get_collection(collection_name=collection_name)
        print(f"ğŸ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ '{collection_name}' í™•ì¸ ì™„ë£Œ")
    except Exception: # ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
        print(f"ğŸ“ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„± ì¤‘...")
        client.create_collection(
            collection_name=collection_name,
            vectors_config=models.VectorParams(
                size=1536,  # text-embedding-3-smallì˜ ë²¡í„° ì°¨ì›
                distance=models.Distance.COSINE
            )
        )
        # ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±
        client.create_payload_index(collection_name=collection_name, field_name="user_id", field_schema="integer")
        client.create_payload_index(collection_name=collection_name, field_name="session_id", field_schema="keyword")
        print(f"ğŸ“ ì»¬ë ‰ì…˜ '{collection_name}' ë° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    # 2. í…ìŠ¤íŠ¸ ì¡°ê°ì„ ë²¡í„°ë¡œ ë³€í™˜
    print("ğŸ¤– í…ìŠ¤íŠ¸ ì¡°ê°ì„ ë²¡í„°ë¡œ ë³€í™˜ ì¤‘...")
    vectors = get_embeddings(embedding_client, chunks)
    
    # 3. Qdrantì— ì €ì¥í•  í¬ì¸íŠ¸(Point) ìƒì„±
    print("ğŸ“¦ í¬ì¸íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
    points = []
    for i, chunk in enumerate(chunks):
        points.append(
            models.PointStruct(
                id=str(uuid.uuid4()), # ê° í¬ì¸íŠ¸ë§ˆë‹¤ ê³ ìœ  ID ìƒì„±
                vector=vectors[i].tolist(), # ë²¡í„°ë¥¼ list í˜•íƒœë¡œ ë³€í™˜
                payload={
                    "text": chunk,
                    "user_id": user_id,
                    "session_id": session_id
                }
            )
        )
        
    # 4. ë°ì´í„° ì—…ì„œíŠ¸(Upsert)
    if points:
        print(f"ğŸ’¾ Qdrantì— {len(points)}ê°œ í¬ì¸íŠ¸ ì—…ì„œíŠ¸ ì¤‘...")
        client.upsert(collection_name=collection_name, points=points, wait=True)
        print(f"âœ… Qdrantì— {len(points)}ê°œì˜ í¬ì¸íŠ¸ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. (user: {user_id}, session: {session_id})")

    print(f"ğŸ upsert_document_to_qdrant í•¨ìˆ˜ ì¢…ë£Œ: {len(points)}ê°œ í¬ì¸íŠ¸ ì €ì¥ ì™„ë£Œ")

def search_qdrant(client: QdrantClient, embedding_client, query: str, user_id: int, session_id: str, top_k=3):
    """
    Qdrantì—ì„œ íŠ¹ì • ì‚¬ìš©ìì˜ íŠ¹ì • ì„¸ì…˜ ë¬¸ì„œë¥¼ ëŒ€ìƒìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ”„ search_qdrant í•¨ìˆ˜ ì‹œì‘: query='{query[:50]}...', user_id={user_id}, session_id={session_id}, top_k={top_k}")
    
    collection_name = "legal_documents"
    
    # 1. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
    print("ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ ì¤‘...")
    query_vector = get_embeddings(embedding_client, [query])[0].tolist()
    
    # 2. í•„í„°(Filter) ìƒì„±: user_idì™€ session_idê°€ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” ë¬¸ì„œë§Œ ê²€ìƒ‰
    print("ğŸ¯ ê²€ìƒ‰ í•„í„° ìƒì„± ì¤‘...")
    query_filter = models.Filter(
        must=[
            models.FieldCondition(key="user_id", match=models.MatchValue(value=user_id)),
            models.FieldCondition(key="session_id", match=models.MatchValue(value=session_id)),
        ]
    )
    
    # 3. ê²€ìƒ‰ ìˆ˜í–‰
    print(f"ğŸ” Qdrant ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘... (ì»¬ë ‰ì…˜: {collection_name})")
    try:
        hits = client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=query_filter,
            limit=top_k
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        results = [hit.payload['text'] for hit in hits]
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜")
        print(f"ğŸ search_qdrant í•¨ìˆ˜ ì¢…ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
        return results
    except Exception as e:
        print(f"âŒ search_qdrant í•¨ìˆ˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


# --- FAISS ì¸ë±ìŠ¤ ìƒì„± (ë¹„íšŒì›ìš©) ---
def create_faiss_index(client, chunks: list[str]):
    """
    í…ìŠ¤íŠ¸ ì¡°ê° ëª©ë¡ì„ ë°›ì•„ ë©”ëª¨ë¦¬ì— FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ”„ create_faiss_index í•¨ìˆ˜ ì‹œì‘: {len(chunks)}ê°œ ì²­í¬")
    
    if not chunks:
        print("âš ï¸ ì²­í¬ê°€ ì—†ì–´ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print("ğŸ create_faiss_index í•¨ìˆ˜ ì¢…ë£Œ: ë¹ˆ ê²°ê³¼ ë°˜í™˜")
        return None, []
    
    print("ğŸ¤– ì²­í¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
    embeddings = get_embeddings(client, chunks)
    if not embeddings:
        print("âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
        print("ğŸ create_faiss_index í•¨ìˆ˜ ì¢…ë£Œ: ë¹ˆ ê²°ê³¼ ë°˜í™˜")
        return None, []
        
    print(f"ğŸ”§ FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘... (ì°¨ì›: {len(embeddings[0])})")
    dimension = len(embeddings[0])
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings))
    
    print(f"âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index.ntotal}ê°œ ë²¡í„° ì¶”ê°€")
    print(f"ğŸ create_faiss_index í•¨ìˆ˜ ì¢…ë£Œ: ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    return index, chunks


# --- FAISS ì¸ë±ìŠ¤ ê²€ìƒ‰ (ë¹„íšŒì›ìš©) ---
def search_faiss_index(index: faiss.Index, chunks: list[str], client, query: str, top_k=3):
    """
    ë©”ëª¨ë¦¬ì˜ FAISS ì¸ë±ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ”„ search_faiss_index í•¨ìˆ˜ ì‹œì‘: query='{query[:50]}...', top_k={top_k}, ì´ {len(chunks)}ê°œ ì²­í¬")
    
    try:
        print("ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
        query_embedding = get_embeddings(client, [query])[0]
        
        print("ğŸ” FAISS ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
        distances, indices = index.search(np.array([query_embedding]), top_k)
        
        results = [chunks[i] for i in indices[0]]
        print(f"âœ… FAISS ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜")
        print(f"ğŸ“Š ê²€ìƒ‰ ê±°ë¦¬: {distances[0].tolist()}")
        print(f"ğŸ search_faiss_index í•¨ìˆ˜ ì¢…ë£Œ: {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ")
        return results
    except Exception as e:
        print(f"âŒ search_faiss_index í•¨ìˆ˜ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise