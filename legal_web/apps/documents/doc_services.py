# teamproject/legal_web/apps/documents/doc_services.py

from openai import OpenAI
from django.conf import settings
from django.contrib.auth.models import AnonymousUser

from . import doc_retriever 
from . import doc_prompt_manager 

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (settings.pyì— OPENAI_API_KEY ì„¤ì •)
client = OpenAI(api_key=settings.OPENAI_API_KEY)
qdrant_client = doc_retriever.get_qdrant_client()

# --- ë¬¸ì„œ ë¶„ì„ ì„œë¹„ìŠ¤ ---
def analyze_document(user, uploaded_file, doc_type, session_id, language='ko'):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìš”ì•½ë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì‚¬ìš©ì ìœ í˜•ì— ë”°ë¼ ë²¡í„° ë°ì´í„°ë¥¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        # 1. íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê¸°ë³¸ ì •ë³´ ì„¤ì •
        document_text = doc_retriever.get_document_text(uploaded_file)
        if not document_text:
            raise ValueError("ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        doc_type_name = "ì´ìš©ì•½ê´€" if doc_type == "terms" else "ê³„ì•½ì„œ"

        # 2. Map-Reduce ë°©ì‹ìœ¼ë¡œ ìš”ì•½ ìƒì„± (ì´ ë¡œì§ì€ íšŒì›/ë¹„íšŒì› ê³µí†µ)
        summary_chunks = doc_retriever.split_text_into_chunks(document_text, max_tokens=2000)
        individual_summaries = []
        for chunk in summary_chunks:
            prompt = doc_prompt_manager.get_summarize_chunk_prompt(chunk, doc_type_name)
            response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "user", "content": prompt}], max_tokens=300, temperature=0.3)
            individual_summaries.append(response.choices[0].message.content)
            
        final_summary_prompt = doc_prompt_manager.get_combine_summaries_prompt(individual_summaries, doc_type_name)
        final_summary_response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "user", "content": final_summary_prompt}], max_tokens=1000, temperature=0.7)
        final_summary = final_summary_response.choices[0].message.content

        # 3. ìœ„í—˜ ìš”ì†Œ ì‹ë³„ (ê³µí†µ)
        risk_prompt = doc_prompt_manager.get_risk_factors_prompt(document_text, language)
        risk_response = client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "user", "content": risk_prompt}], max_tokens=1000, temperature=0.3)
        risk_text = risk_response.choices[0].message.content

        # 4. QAë¥¼ ìœ„í•œ ì²­í¬ ì¤€ë¹„
        qa_chunks = doc_retriever.split_text_into_chunks(document_text, max_tokens=500)
        
        # 5. â˜…â˜…â˜… ì‚¬ìš©ì ìœ í˜•ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬ â˜…â˜…â˜…
        if isinstance(user, AnonymousUser):
            # --- ë¹„íšŒì›ì¸ ê²½ìš°: FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜ ---
            faiss_index, indexed_chunks = doc_retriever.create_faiss_index(client, qa_chunks)
            storage_data = {"type": "faiss", "index": faiss_index, "chunks": indexed_chunks}
            print(f"ë¹„íšŒì› ë¶„ì„ ì™„ë£Œ. FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        else:
            # --- íšŒì›ì¸ ê²½ìš°: Qdrantì— ë²¡í„°ë¥¼ ì €ì¥ ---
            doc_retriever.upsert_document_to_qdrant(qdrant_client, qa_chunks, client, user.id, session_id)
            storage_data = {"type": "qdrant"} # QdrantëŠ” ë³„ë„ ë°˜í™˜ ë°ì´í„° ì—†ìŒ
            print(f"íšŒì›(id:{user.id}) ë¶„ì„ ì™„ë£Œ. Qdrantì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            
        # 6. ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "success": True,
            "summary": f"ğŸ“‹ ë¬¸ì„œ ìš”ì•½\n\n{final_summary}\n\n---\n\nâš ï¸ ìœ„í—˜ ìš”ì†Œ ì‹ë³„\n\n{risk_text}",
            "storage_data": storage_data # ì €ì¥ ë°©ì‹ê³¼ ë°ì´í„°ë¥¼ í•¨ê»˜ ì „ë‹¬
        }

    except Exception as e:
        print(f"Error in analyze_document service: {e}")
        return {"success": False, "error": str(e)}

