# teamproject/legal_web/apps/documents/doc_services.py

from openai import OpenAI, APIError
from django.conf import settings
from django.contrib.auth.models import AnonymousUser

from . import doc_retriever 
from . import doc_prompt_manager 

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (settings.pyì— OPENAI_API_KEY ì„¤ì •)
client = OpenAI(api_key=settings.OPENAI_API_KEY)
qdrant_client = doc_retriever.get_qdrant_client()




def _translate_text(text: str, target_lang_name: str) -> str:
    """
    ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜.
    """
    if not text or target_lang_name == "í•œêµ­ì–´":
        return text
    try:
        prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {target_lang_name}ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ì›ë¬¸ì˜ ì„œì‹(ì¤„ë°”ê¿ˆ, ê¸€ë¨¸ë¦¬ ê¸°í˜¸ ë“±)ì„ ìµœëŒ€í•œ ìœ ì§€í•´ì£¼ì„¸ìš”:\n\n---\n{text}"
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2, # ë²ˆì—­ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ë¡œ ì„¤ì •
        )
        return response.choices[0].message.content.strip()
    except APIError as e:
        print(f"OpenAI API Error during translation: {e}")
        # API ì˜¤ë¥˜ ë°œìƒ ì‹œ, ë²ˆì—­ ì‹¤íŒ¨ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì›ë¬¸ ë°˜í™˜
        return f"({target_lang_name} ë²ˆì—­ ì‹¤íŒ¨: API ì˜¤ë¥˜) {text}"
    except Exception as e:
        print(f"Unexpected error during translation: {e}")
        return f"({target_lang_name} ë²ˆì—­ ì‹¤íŒ¨: ì‹œìŠ¤í…œ ì˜¤ë¥˜) {text}"

        
        

# --- ë¬¸ì„œ ë¶„ì„ ì„œë¹„ìŠ¤ --- 
def analyze_document(user, uploaded_file, doc_type, session_id, language='ko'):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³ , API ì˜¤ë¥˜ë¥¼ í¬í•¨í•œ ëª¨ë“  ì˜ˆì™¸ë¥¼
    ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ëª…í™•í•œ JSON ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # --- 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
        document_text = doc_retriever.get_document_text(uploaded_file)
        if not document_text:
            raise ValueError("ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        doc_type_name = "ì´ìš©ì•½ê´€" if doc_type == "terms" else "ê³„ì•½ì„œ"

        # --- 2. í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ìš”ì•½ ë° ìœ„í—˜ ìš”ì†Œ ë¶„ì„ ---
        print("Step 1: Analyzing document with Chat Completions API...")
        summary_chunks = doc_retriever.split_text_into_chunks(document_text, max_tokens=2000)
        individual_summaries = [
            client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": doc_prompt_manager.get_summarize_chunk_prompt(chunk, doc_type_name)}],
                max_tokens=300, temperature=0.3
            ).choices[0].message.content
            for chunk in summary_chunks
        ]
        final_summary_ko_prompt = doc_prompt_manager.get_combine_summaries_prompt(individual_summaries, doc_type_name)
        final_summary_ko = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": final_summary_ko_prompt}],
            max_tokens=1000, temperature=0.7
        ).choices[0].message.content
        risk_text_ko_prompt = doc_prompt_manager.get_risk_factors_prompt(document_text)
        risk_text_ko = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": risk_text_ko_prompt}],
            max_tokens=1000, temperature=0.3
        ).choices[0].message.content
        
        # --- 3. ì„ íƒëœ ì–¸ì–´ë¡œ ê²°ê³¼ ë²ˆì—­ ---
        print("Step 2: Translating results if necessary...")
        final_summary_lang, risk_text_lang = final_summary_ko, risk_text_ko
        lang_map = {'en': 'English', 'es': 'Spanish', 'ja': 'ì¼ë³¸ì–´', 'zh': 'ì¤‘êµ­ì–´'}
        if language in lang_map:
            target_lang_name = lang_map[language]
            final_summary_lang = _translate_text(final_summary_ko, target_lang_name)
            risk_text_lang = _translate_text(risk_text_ko, target_lang_name)

        # --- 4. QAë¥¼ ìœ„í•œ ë²¡í„°í™” ---
        print("Step 3: Vectorizing document with Embeddings API...")
        qa_chunks = doc_retriever.split_text_into_chunks(document_text, max_tokens=500)
        
        if isinstance(user, AnonymousUser):
            faiss_index, indexed_chunks = doc_retriever.create_faiss_index(client, qa_chunks)
            storage_data = {"type": "faiss", "index": faiss_index, "chunks": indexed_chunks}
        else:
            doc_retriever.upsert_document_to_qdrant(qdrant_client, qa_chunks, client, user.id, session_id)
            storage_data = {"type": "qdrant"}

        # --- 5. ëª¨ë“  ê²ƒì´ ì„±ê³µí–ˆì„ ë•Œì˜ ìµœì¢… ê²°ê³¼ ë°˜í™˜ ---
        return {
            "success": True,
            "summary": f"ğŸ“‹ ë¬¸ì„œ ìš”ì•½\n\n{final_summary_lang}\n\n---\n\nâš ï¸ ìœ„í—˜ ìš”ì†Œ ì‹ë³„\n\n{risk_text_lang}",
            "storage_data": storage_data
        }


    except APIError as e:
        # OpenAIì—ì„œ ë³´ë‚¸ ì—ëŸ¬ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ëª…í™•í•œ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        error_message = f"AI ëª¨ë¸ í†µì‹  ì˜¤ë¥˜ (ìƒíƒœ ì½”ë“œ: {e.status_code})"
        if e.code == 'insufficient_quota':
            error_message = "AI ì„œë¹„ìŠ¤ ì‚¬ìš© í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        
        print(f"[ERROR] OpenAI API Error occurred: {e}")
        # ì„œë²„ê°€ ì£½ëŠ” ëŒ€ì‹ , ì •ìƒì ì¸ JSON ì—ëŸ¬ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        return {"success": False, "error": error_message}
    
    # ê·¸ ì™¸ ëª¨ë“  ì˜ˆì™¸(íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ë“±)ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    except Exception as e:
        print(f"[ERROR] Unexpected error occurred: {e}")
        return {"success": False, "error": f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}
